{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simpliest usage example of py_boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation (if needed)\n",
    "\n",
    "**Note**: replace cupy-cuda110 with your cuda version!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda110 py-boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# simple case - just one class is used\n",
    "from py_boost import GradientBoosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of dummy regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 1.66 s, total: 3.67 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=10, random_state=42)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a GBDT model\n",
    "\n",
    "The only argument required here is a loss function. It, together with the input target shape, determines the task type. The loss function can be passed as a Loss instance or using a string alias:\n",
    "\n",
    "* ***'mse'*** for the regression/multitask regression\n",
    "* ***'msle'*** for the regression/multitask regression\n",
    "* ***'bce'*** for the binary/multilabel classification\n",
    "* ***'crossentropy'*** for the multiclassification\n",
    "\n",
    "Training is simply done by calling the .fit metod. Possible argumentsare the following:\n",
    "\n",
    "* ***'X'*** \n",
    "* ***'y'*** \n",
    "* ***'sample_weight'*** \n",
    "* ***'eval_sets'***  \n",
    "A validation set is passed as a list of dicts with possible keys ['X', 'y', 'sample_weight']. Note: if multiple valid sets are passed, the best model is selected using the last one.\n",
    "\n",
    "#### The example below illustrates how to train a simple regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:31] Stdout logging level is INFO.\n",
      "[22:56:31] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[22:56:31] Iter 0; Sample 0, rmse = 173.67502273618487; \n",
      "[22:56:31] Iter 10; Sample 0, rmse = 133.19549011443806; \n",
      "[22:56:31] Iter 20; Sample 0, rmse = 107.8665815634426; \n",
      "[22:56:31] Iter 30; Sample 0, rmse = 90.0826883436304; \n",
      "[22:56:31] Iter 40; Sample 0, rmse = 76.4457603762527; \n",
      "[22:56:32] Iter 50; Sample 0, rmse = 65.61088819266847; \n",
      "[22:56:32] Iter 60; Sample 0, rmse = 56.80212578800188; \n",
      "[22:56:32] Iter 70; Sample 0, rmse = 49.57775349232627; \n",
      "[22:56:32] Iter 80; Sample 0, rmse = 43.60446814035017; \n",
      "[22:56:32] Iter 90; Sample 0, rmse = 38.698434828148464; \n",
      "[22:56:32] Iter 99; Sample 0, rmse = 34.99265881928977; \n",
      "CPU times: user 2.64 s, sys: 25 ms, total: 2.67 s\n",
      "Wall time: 1.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f167c29d910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse')\n",
    "\n",
    "model.fit(X, y[:, 0], eval_sets=[{'X': X_test, 'y': y_test[:, 0]},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traininig a GBDT model in a multiregression case\n",
    "\n",
    "Each of built-in loss functions has its own default metric, so metric definition is optional. \n",
    "If you need to specify the evaluation metric, you can pass a Metric instance or use a string alias.\n",
    "\n",
    "#### Default metrics:\n",
    "\n",
    "* ***'rmse'*** is the default for the ***'mse'*** loss\n",
    "* ***'rmsle'*** is the default for the  ***'msle'*** loss\n",
    "* ***'bce'*** is the default for the ***'bce'*** loss\n",
    "* ***'crossentropy'*** is the default for the ***'crossentropy'*** loss\n",
    "\n",
    "#### Non-default metrics:\n",
    "\n",
    "* ***'r2'*** for the regression/multitask regression\n",
    "* ***'auc'*** for the binary classification\n",
    "* ***'accuracy'*** for any classification task\n",
    "* ***'precision'*** for any classification task\n",
    "* ***'recall'*** for any classification task\n",
    "* ***'f1'*** for any classification task\n",
    "\n",
    "It is possible to specify other common GBDT hyperparameters as shown below.\n",
    "\n",
    "#### The following example demonstrates how to train a model for a multioutput regression task (no extra definition needed to switch the task to multioutput one, you just need to pass a multidimensional target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:35] Stdout logging level is INFO.\n",
      "[22:56:35] GDBT train starts. Max iter 1000, early stopping rounds 200\n",
      "[22:56:35] Iter 0; Sample 0, R2_score = 0.00838493382121076; \n",
      "[22:56:37] Iter 100; Sample 0, R2_score = 0.5168178350036745; \n",
      "[22:56:39] Iter 200; Sample 0, R2_score = 0.7242543017807709; \n",
      "[22:56:42] Iter 300; Sample 0, R2_score = 0.8327236690102027; \n",
      "[22:56:44] Iter 400; Sample 0, R2_score = 0.8949888496073136; \n",
      "[22:56:46] Iter 500; Sample 0, R2_score = 0.932081267698251; \n",
      "[22:56:48] Iter 600; Sample 0, R2_score = 0.9547251100659679; \n",
      "[22:56:50] Iter 700; Sample 0, R2_score = 0.968778829828431; \n",
      "[22:56:52] Iter 800; Sample 0, R2_score = 0.9776492835117481; \n",
      "[22:56:54] Iter 900; Sample 0, R2_score = 0.9833336498217328; \n",
      "[22:56:57] Iter 999; Sample 0, R2_score = 0.9870174981643824; \n",
      "CPU times: user 20.4 s, sys: 2.93 s, total: 23.3 s\n",
      "Wall time: 22.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f14597e3af0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', 'r2_score',\n",
    "                         ntrees=1000, lr=.01, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10, min_gain_to_split=0, \n",
    "                         max_bin=256, max_depth=6)\n",
    "\n",
    "model.fit(X, y, eval_sets=[{'X': X_test, 'y': y_test},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "#### Prediction can be done via calling the .predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 699 ms, sys: 538 ms, total: 1.24 s\n",
      "Wall time: 1.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-242.54619  , -150.13025  , -284.54285  , ..., -147.102    ,\n",
       "        -219.06776  , -237.3776   ],\n",
       "       [-121.74027  , -119.706116 ,  -63.835587 , ..., -133.57527  ,\n",
       "        -122.1771   ,  -25.195803 ],\n",
       "       [ -32.62834  ,  -53.10981  ,  147.76602  , ...,   22.266607 ,\n",
       "         -18.788473 , -206.22401  ],\n",
       "       ...,\n",
       "       [ -85.29818  ,  130.21333  ,   85.10849  , ...,  222.686    ,\n",
       "          30.748068 ,   10.428176 ],\n",
       "       [  -5.4758997,  142.11945  ,  245.6441   , ...,  152.84828  ,\n",
       "         177.40526  ,  208.26883  ],\n",
       "       [ -20.150242 ,   34.07326  ,  165.9649   , ...,   93.3193   ,\n",
       "          20.594887 ,    3.8033602]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for certan iterations can be done via calling the .predict_staged method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 366 ms, sys: 257 ms, total: 623 ms\n",
      "Wall time: 639 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_staged(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree leaves indicies prediction for certan iterations can be done via calling the .predict_leaves method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 ms, sys: 0 ns, total: 17.4 ms\n",
      "Wall time: 16.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_leaves(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 41, 15],\n",
       "       [54, 41, 26],\n",
       "       [32, 41, 17],\n",
       "       ...,\n",
       "       [54, 47, 22],\n",
       "       [27, 41, 21],\n",
       "       [60, 41, 26]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  55.,   40.,   32.,   29.,   70.,   53., 5580.,   39.,   49.,\n",
       "         62.,   29.,   58.,   44.,   44.,   43., 5988., 5433.,   42.,\n",
       "         38., 5545.,   46.,   43.,   50.,   75.,   33.,   36.,   47.,\n",
       "         50.,   46.,   45.,   46.,   51.,   52.,   60.,   37.,   44.,\n",
       "       6047.,   45.,   47.,   41.,   55.,   39.,   62.,   37.,   39.,\n",
       "         43.,   45.,   48.,   45.,   52.,   51.,   49., 5913.,   37.,\n",
       "         51.,   56.,   39.,   25.,   32.,   48.,   57.,   49.,   46.,\n",
       "         40.,   58.,   33.,   41.,   43.,   35.,   58.,   33.,   44.,\n",
       "         43.,   38.,   31.,   52.,   55.,   40.,   39.,   50.,   58.,\n",
       "         44.,   29.,   37.,   61.,   40., 5613., 3633.,   40., 5774.,\n",
       "         41., 6149.,   36.,   57.,   47.,   48.,   40.,   64.,   36.,\n",
       "         55.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The trained model can be saved as pickle for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-240.81075  , -148.83202  , -280.99615  , ..., -142.74734  ,\n",
       "        -214.31436  , -236.81242  ],\n",
       "       [-108.171936 , -109.24172  ,  -60.211185 , ..., -125.89796  ,\n",
       "        -117.73771  ,  -18.45293  ],\n",
       "       [ -35.97747  ,  -56.86327  ,  143.64543  , ...,   17.656034 ,\n",
       "         -24.660435 , -208.64627  ],\n",
       "       ...,\n",
       "       [ -76.424126 ,  131.95796  ,   76.04112  , ...,  221.9448   ,\n",
       "          33.135143 ,   12.766483 ],\n",
       "       [  -4.4583893,  142.41664  ,  250.57855  , ...,  153.35132  ,\n",
       "         178.4664   ,  211.33765  ],\n",
       "       [ -21.81873  ,   32.88923  ,  168.96144  , ...,   93.069725 ,\n",
       "          22.013023 ,    3.3425033]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, '../data/temp_model.pkl')\n",
    "\n",
    "new_model = joblib.load('../data/temp_model.pkl')\n",
    "new_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.04",
   "language": "python",
   "name": "rapids-22.04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
