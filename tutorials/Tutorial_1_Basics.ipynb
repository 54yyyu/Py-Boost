{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simpliest usage example of py_boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation (if needed)\n",
    "\n",
    "**Note**: replace cupy-cuda110 with your cuda version!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda110 py-boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "\n",
    "# simple case - just one class is used\n",
    "from py_boost import GradientBoosting\n",
    "from py_boost.cv import CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of dummy regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.43 s, sys: 1.48 s, total: 3.91 s\n",
      "Wall time: 811 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=10, random_state=42)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a GBDT model\n",
    "\n",
    "The only argument required here is a loss function. It, together with the input target shape, determines the task type. The loss function can be passed as a Loss instance or using a string alias:\n",
    "\n",
    "* ***'mse'*** for the regression/multitask regression\n",
    "* ***'msle'*** for the regression/multitask regression\n",
    "* ***'bce'*** for the binary/multilabel classification\n",
    "* ***'crossentropy'*** for the multiclassification\n",
    "\n",
    "Training is simply done by calling the .fit metod. Possible argumentsare the following:\n",
    "\n",
    "* ***'X'*** \n",
    "* ***'y'*** \n",
    "* ***'sample_weight'*** \n",
    "* ***'eval_sets'***  \n",
    "A validation set is passed as a list of dicts with possible keys ['X', 'y', 'sample_weight']. Note: if multiple valid sets are passed, the best model is selected using the last one.\n",
    "\n",
    "#### The example below illustrates how to train a simple regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:49] Stdout logging level is INFO.\n",
      "[20:52:49] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[20:52:49] Iter 0; Sample 0, rmse = 173.68515683069276; \n",
      "[20:52:49] Iter 10; Sample 0, rmse = 133.23295041730694; \n",
      "[20:52:49] Iter 20; Sample 0, rmse = 107.90963543511216; \n",
      "[20:52:50] Iter 30; Sample 0, rmse = 90.08342819554207; \n",
      "[20:52:50] Iter 40; Sample 0, rmse = 76.43017533279323; \n",
      "[20:52:50] Iter 50; Sample 0, rmse = 65.5577889119952; \n",
      "[20:52:50] Iter 60; Sample 0, rmse = 56.76787553118689; \n",
      "[20:52:50] Iter 70; Sample 0, rmse = 49.564956655108595; \n",
      "[20:52:50] Iter 80; Sample 0, rmse = 43.58867561316726; \n",
      "[20:52:50] Iter 90; Sample 0, rmse = 38.67175787149395; \n",
      "[20:52:50] Iter 99; Sample 0, rmse = 34.99754081347279; \n",
      "CPU times: user 7.27 s, sys: 962 ms, total: 8.23 s\n",
      "Wall time: 6.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f486e3eba90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse')\n",
    "\n",
    "model.fit(X, y[:, 0], eval_sets=[{'X': X_test, 'y': y_test[:, 0]},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traininig a GBDT model in a multiregression case\n",
    "\n",
    "Each of built-in loss functions has its own default metric, so metric definition is optional. \n",
    "If you need to specify the evaluation metric, you can pass a Metric instance or use a string alias.\n",
    "\n",
    "#### Default metrics:\n",
    "\n",
    "* ***'rmse'*** is the default for the ***'mse'*** loss\n",
    "* ***'rmsle'*** is the default for the  ***'msle'*** loss\n",
    "* ***'bce'*** is the default for the ***'bce'*** loss\n",
    "* ***'crossentropy'*** is the default for the ***'crossentropy'*** loss\n",
    "\n",
    "#### Non-default metrics:\n",
    "\n",
    "* ***'r2'*** for the regression/multitask regression\n",
    "* ***'auc'*** for the binary classification\n",
    "* ***'accuracy'*** for any classification task\n",
    "* ***'precision'*** for any classification task\n",
    "* ***'recall'*** for any classification task\n",
    "* ***'f1'*** for any classification task\n",
    "\n",
    "It is possible to specify other common GBDT hyperparameters as shown below.\n",
    "\n",
    "#### The following example demonstrates how to train a model for a multioutput regression task (no extra definition needed to switch the task to multioutput one, you just need to pass a multidimensional target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:50] Stdout logging level is INFO.\n",
      "[20:52:50] GDBT train starts. Max iter 1000, early stopping rounds 200\n",
      "[20:52:50] Iter 0; Sample 0, R2_score = 0.008394434412401175; \n",
      "[20:52:52] Iter 100; Sample 0, R2_score = 0.5168091229427232; \n",
      "[20:52:54] Iter 200; Sample 0, R2_score = 0.7243334810252653; \n",
      "[20:52:56] Iter 300; Sample 0, R2_score = 0.8326970487914259; \n",
      "[20:52:58] Iter 400; Sample 0, R2_score = 0.8950369225819286; \n",
      "[20:53:00] Iter 500; Sample 0, R2_score = 0.9321446308026127; \n",
      "[20:53:02] Iter 600; Sample 0, R2_score = 0.9547326078219325; \n",
      "[20:53:04] Iter 700; Sample 0, R2_score = 0.9687759168879175; \n",
      "[20:53:06] Iter 800; Sample 0, R2_score = 0.9776385294523188; \n",
      "[20:53:08] Iter 900; Sample 0, R2_score = 0.9833225210195948; \n",
      "[20:53:10] Iter 999; Sample 0, R2_score = 0.9870099055456798; \n",
      "CPU times: user 19.6 s, sys: 2.7 s, total: 22.3 s\n",
      "Wall time: 20.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f486e3eb8e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', 'r2_score',\n",
    "                         ntrees=1000, lr=.01, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10, min_gain_to_split=0, \n",
    "                         max_bin=256, max_depth=6)\n",
    "\n",
    "model.fit(X, y, eval_sets=[{'X': X_test, 'y': y_test},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "#### Prediction can be done via calling the .predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 505 ms, total: 1.74 s\n",
      "Wall time: 1.75 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-230.07994  , -139.01242  , -271.89752  , ..., -132.4745   ,\n",
       "        -209.56622  , -227.33429  ],\n",
       "       [-105.2129   , -105.53808  ,  -51.97523  , ..., -121.95376  ,\n",
       "        -110.97196  ,  -13.6838045],\n",
       "       [ -39.22138  ,  -58.721336 ,  142.582    , ...,   17.447527 ,\n",
       "         -23.655943 , -213.7487   ],\n",
       "       ...,\n",
       "       [ -81.388824 ,  130.64673  ,   79.12572  , ...,  222.39725  ,\n",
       "          31.501627 ,    8.980256 ],\n",
       "       [  -3.883288 ,  139.77042  ,  247.42499  , ...,  150.47414  ,\n",
       "         175.14754  ,  207.02196  ],\n",
       "       [  -8.103888 ,   40.226532 ,  169.67625  , ...,   95.37619  ,\n",
       "          27.459566 ,   11.250004 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for certan iterations can be done via calling the .predict_staged method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 342 ms, sys: 247 ms, total: 589 ms\n",
      "Wall time: 596 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_staged(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree leaves indicies prediction for certan iterations can be done via calling the .predict_leaves method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 ms, sys: 276 µs, total: 17.4 ms\n",
      "Wall time: 16.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_leaves(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 20,  9],\n",
       "       [50, 43, 23],\n",
       "       [32, 43, 55],\n",
       "       ...,\n",
       "       [54, 50,  9],\n",
       "       [30, 43, 19],\n",
       "       [60, 43, 23]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  37.,   35.,   35.,   49.,   59.,   49., 5586.,   50.,   56.,\n",
       "         55.,   46.,   52.,   50.,   45.,   46., 5947., 5505.,   40.,\n",
       "         54., 5439.,   37.,   43.,   47.,   83.,   31.,   48.,   40.,\n",
       "         47.,   50.,   49.,   58.,   63.,   52.,   59.,   51.,   46.,\n",
       "       6010.,   38.,   45.,   47.,   69.,   47.,   63.,   37.,   43.,\n",
       "         46.,   43.,   33.,   41.,   44.,   36.,   55., 5914.,   52.,\n",
       "         48.,   53.,   50.,   40.,   47.,   39.,   55.,   52.,   49.,\n",
       "         52.,   57.,   36.,   53.,   50.,   36.,   44.,   45.,   37.,\n",
       "         37.,   50.,   52.,   46.,   55.,   34.,   47.,   41.,   57.,\n",
       "         45.,   31.,   49.,   45.,   27., 5487., 3544.,   47., 5797.,\n",
       "         40., 6244.,   34.,   47.,   63.,   41.,   36.,   51.,   45.,\n",
       "         52.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The trained model can be saved as pickle for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-230.07994  , -139.01242  , -271.89752  , ..., -132.4745   ,\n",
       "        -209.56622  , -227.33429  ],\n",
       "       [-105.2129   , -105.53808  ,  -51.97523  , ..., -121.95376  ,\n",
       "        -110.97196  ,  -13.6838045],\n",
       "       [ -39.22138  ,  -58.721336 ,  142.582    , ...,   17.447527 ,\n",
       "         -23.655943 , -213.7487   ],\n",
       "       ...,\n",
       "       [ -81.388824 ,  130.64673  ,   79.12572  , ...,  222.39725  ,\n",
       "          31.501627 ,    8.980256 ],\n",
       "       [  -3.883288 ,  139.77042  ,  247.42499  , ...,  150.47414  ,\n",
       "         175.14754  ,  207.02196  ],\n",
       "       [  -8.103888 ,   40.226532 ,  169.67625  , ...,   95.37619  ,\n",
       "          27.459566 ,   11.250004 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, '../data/temp_model.pkl')\n",
    "\n",
    "new_model = joblib.load('../data/temp_model.pkl')\n",
    "new_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "Also py_boost supports built in cross validation wrapper that produce out-of-fold prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:16] Stdout logging level is INFO.\n",
      "[20:53:16] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[20:53:16] Iter 0; Sample 0, rmse = 176.17283883265787; \n",
      "[20:53:16] Iter 10; Sample 0, rmse = 144.64857862576474; \n",
      "[20:53:16] Iter 20; Sample 0, rmse = 122.80526576817687; \n",
      "[20:53:16] Iter 30; Sample 0, rmse = 106.20694134133124; \n",
      "[20:53:17] Iter 40; Sample 0, rmse = 93.03256160556448; \n",
      "[20:53:17] Iter 50; Sample 0, rmse = 82.3056986784575; \n",
      "[20:53:17] Iter 60; Sample 0, rmse = 73.12733773653729; \n",
      "[20:53:17] Iter 70; Sample 0, rmse = 65.30923174734228; \n",
      "[20:53:17] Iter 80; Sample 0, rmse = 58.71652095411406; \n",
      "[20:53:18] Iter 90; Sample 0, rmse = 53.02306242586308; \n",
      "[20:53:18] Iter 99; Sample 0, rmse = 48.52981207400637; \n",
      "[20:53:18] Stdout logging level is INFO.\n",
      "[20:53:18] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[20:53:18] Iter 0; Sample 0, rmse = 176.1975859432932; \n",
      "[20:53:18] Iter 10; Sample 0, rmse = 144.97434053387218; \n",
      "[20:53:18] Iter 20; Sample 0, rmse = 123.06225882484506; \n",
      "[20:53:19] Iter 30; Sample 0, rmse = 106.44354859942317; \n",
      "[20:53:19] Iter 40; Sample 0, rmse = 93.29705479128421; \n",
      "[20:53:19] Iter 50; Sample 0, rmse = 82.42604951167559; \n",
      "[20:53:19] Iter 60; Sample 0, rmse = 73.25854039529924; \n",
      "[20:53:19] Iter 70; Sample 0, rmse = 65.4349212957046; \n",
      "[20:53:20] Iter 80; Sample 0, rmse = 58.82048139246293; \n",
      "[20:53:20] Iter 90; Sample 0, rmse = 53.06078765142427; \n",
      "[20:53:20] Iter 99; Sample 0, rmse = 48.59650031936322; \n",
      "[20:53:20] Stdout logging level is INFO.\n",
      "[20:53:20] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[20:53:20] Iter 0; Sample 0, rmse = 175.58643987498078; \n",
      "[20:53:20] Iter 10; Sample 0, rmse = 144.3558972690621; \n",
      "[20:53:21] Iter 20; Sample 0, rmse = 122.49607831535045; \n",
      "[20:53:21] Iter 30; Sample 0, rmse = 105.94798229126923; \n",
      "[20:53:21] Iter 40; Sample 0, rmse = 92.88303302028433; \n",
      "[20:53:21] Iter 50; Sample 0, rmse = 82.11550850384582; \n",
      "[20:53:21] Iter 60; Sample 0, rmse = 73.03259734392716; \n",
      "[20:53:22] Iter 70; Sample 0, rmse = 65.23208027240248; \n",
      "[20:53:22] Iter 80; Sample 0, rmse = 58.55052629035978; \n",
      "[20:53:22] Iter 90; Sample 0, rmse = 52.91080161925499; \n",
      "[20:53:22] Iter 99; Sample 0, rmse = 48.42504633495842; \n",
      "[20:53:22] Stdout logging level is INFO.\n",
      "[20:53:22] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[20:53:22] Iter 0; Sample 0, rmse = 176.85729950921456; \n",
      "[20:53:23] Iter 10; Sample 0, rmse = 145.69214912528278; \n",
      "[20:53:23] Iter 20; Sample 0, rmse = 123.8381047206578; \n",
      "[20:53:23] Iter 30; Sample 0, rmse = 107.30699526324113; \n",
      "[20:53:23] Iter 40; Sample 0, rmse = 94.08970229403414; \n",
      "[20:53:23] Iter 50; Sample 0, rmse = 83.2242147992599; \n",
      "[20:53:24] Iter 60; Sample 0, rmse = 74.05289293932707; \n",
      "[20:53:24] Iter 70; Sample 0, rmse = 66.23151456624117; \n",
      "[20:53:24] Iter 80; Sample 0, rmse = 59.515634868437985; \n",
      "[20:53:24] Iter 90; Sample 0, rmse = 53.76514762102698; \n",
      "[20:53:24] Iter 99; Sample 0, rmse = 49.32209998845068; \n",
      "[20:53:25] Stdout logging level is INFO.\n",
      "[20:53:25] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[20:53:25] Iter 0; Sample 0, rmse = 175.35243674884995; \n",
      "[20:53:25] Iter 10; Sample 0, rmse = 144.56059535077316; \n",
      "[20:53:25] Iter 20; Sample 0, rmse = 123.00712526349426; \n",
      "[20:53:25] Iter 30; Sample 0, rmse = 106.55815723960696; \n",
      "[20:53:25] Iter 40; Sample 0, rmse = 93.48897936438505; \n",
      "[20:53:26] Iter 50; Sample 0, rmse = 82.62209636902674; \n",
      "[20:53:26] Iter 60; Sample 0, rmse = 73.42567492946047; \n",
      "[20:53:26] Iter 70; Sample 0, rmse = 65.65138559665743; \n",
      "[20:53:26] Iter 80; Sample 0, rmse = 58.99984454516359; \n",
      "[20:53:26] Iter 90; Sample 0, rmse = 53.287174765014875; \n",
      "[20:53:27] Iter 99; Sample 0, rmse = 48.8161830559525; \n",
      "CPU times: user 11.6 s, sys: 1.57 s, total: 13.2 s\n",
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.2994203961322"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse')\n",
    "cv = CrossValidation(model)\n",
    "\n",
    "oof_pred = cv.fit_predict(X, y, cv=5)\n",
    "\n",
    "pred = cv.predict(X_test)\n",
    "((pred - y_test) ** 2).mean() ** .5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.04",
   "language": "python",
   "name": "rapids-22.04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
