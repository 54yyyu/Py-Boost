{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simpliest usage example of py_boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation (if needed)\n",
    "\n",
    "**Note**: replace cupy-cuda110 with your cuda version!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda110 py-boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "\n",
    "# simple case - just one class is used\n",
    "from py_boost import GradientBoosting\n",
    "from py_boost.cv import CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of dummy regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 1.6 s, total: 3.92 s\n",
      "Wall time: 813 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=10, random_state=42)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a GBDT model\n",
    "\n",
    "The only argument required here is a loss function. It, together with the input target shape, determines the task type. The loss function can be passed as a Loss instance or using a string alias:\n",
    "\n",
    "* ***'mse'*** for the regression/multitask regression\n",
    "* ***'msle'*** for the regression/multitask regression\n",
    "* ***'bce'*** for the binary/multilabel classification\n",
    "* ***'crossentropy'*** for the multiclassification\n",
    "\n",
    "Training is simply done by calling the .fit metod. Possible argumentsare the following:\n",
    "\n",
    "* ***'X'*** \n",
    "* ***'y'*** \n",
    "* ***'sample_weight'*** \n",
    "* ***'eval_sets'***  \n",
    "A validation set is passed as a list of dicts with possible keys ['X', 'y', 'sample_weight']. Note: if multiple valid sets are passed, the best model is selected using the last one.\n",
    "\n",
    "#### The example below illustrates how to train a simple regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:05:38] Stdout logging level is INFO.\n",
      "[10:05:38] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[10:05:39] Iter 0; Sample 0, rmse = 173.68515689890785; \n",
      "[10:05:39] Iter 10; Sample 0, rmse = 133.2329134694332; \n",
      "[10:05:39] Iter 20; Sample 0, rmse = 107.90957666785495; \n",
      "[10:05:39] Iter 30; Sample 0, rmse = 90.08412889111113; \n",
      "[10:05:39] Iter 40; Sample 0, rmse = 76.43090124568918; \n",
      "[10:05:39] Iter 50; Sample 0, rmse = 65.558451192956; \n",
      "[10:05:40] Iter 60; Sample 0, rmse = 56.768458988756876; \n",
      "[10:05:40] Iter 70; Sample 0, rmse = 49.56556837526753; \n",
      "[10:05:40] Iter 80; Sample 0, rmse = 43.589192766231506; \n",
      "[10:05:40] Iter 90; Sample 0, rmse = 38.672162024198634; \n",
      "[10:05:40] Iter 99; Sample 0, rmse = 34.99783732571031; \n",
      "CPU times: user 8.95 s, sys: 1.34 s, total: 10.3 s\n",
      "Wall time: 7.95 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f0374b0e670>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse')\n",
    "\n",
    "model.fit(X, y[:, 0], eval_sets=[{'X': X_test, 'y': y_test[:, 0]},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traininig a GBDT model in a multiregression case\n",
    "\n",
    "Each of built-in loss functions has its own default metric, so metric definition is optional. \n",
    "If you need to specify the evaluation metric, you can pass a Metric instance or use a string alias.\n",
    "\n",
    "#### Default metrics:\n",
    "\n",
    "* ***'rmse'*** is the default for the ***'mse'*** loss\n",
    "* ***'rmsle'*** is the default for the  ***'msle'*** loss\n",
    "* ***'bce'*** is the default for the ***'bce'*** loss\n",
    "* ***'crossentropy'*** is the default for the ***'crossentropy'*** loss\n",
    "\n",
    "#### Non-default metrics:\n",
    "\n",
    "* ***'r2'*** for the regression/multitask regression\n",
    "* ***'auc'*** for the binary classification\n",
    "* ***'accuracy'*** for any classification task\n",
    "* ***'precision'*** for any classification task\n",
    "* ***'recall'*** for any classification task\n",
    "* ***'f1'*** for any classification task\n",
    "\n",
    "It is possible to specify other common GBDT hyperparameters as shown below.\n",
    "\n",
    "#### The following example demonstrates how to train a model for a multioutput regression task (no extra definition needed to switch the task to multioutput one, you just need to pass a multidimensional target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:05:40] Stdout logging level is INFO.\n",
      "[10:05:40] GDBT train starts. Max iter 1000, early stopping rounds 200\n",
      "[10:05:42] Iter 0; Sample 0, R2_score = 0.008394434444722109; \n",
      "[10:05:44] Iter 100; Sample 0, R2_score = 0.5168089065694275; \n",
      "[10:05:46] Iter 200; Sample 0, R2_score = 0.7243047110486456; \n",
      "[10:05:48] Iter 300; Sample 0, R2_score = 0.8328610027909523; \n",
      "[10:05:51] Iter 400; Sample 0, R2_score = 0.8950558515671254; \n",
      "[10:05:53] Iter 500; Sample 0, R2_score = 0.9320911339106711; \n",
      "[10:05:55] Iter 600; Sample 0, R2_score = 0.9547420897045367; \n",
      "[10:05:57] Iter 700; Sample 0, R2_score = 0.9687934126955178; \n",
      "[10:05:59] Iter 800; Sample 0, R2_score = 0.9776687079713445; \n",
      "[10:06:02] Iter 900; Sample 0, R2_score = 0.9833495654282334; \n",
      "[10:06:04] Iter 999; Sample 0, R2_score = 0.9870432315097194; \n",
      "CPU times: user 23.4 s, sys: 2.24 s, total: 25.6 s\n",
      "Wall time: 23.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f035e2a39a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', 'r2_score',\n",
    "                         ntrees=1000, lr=.01, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10, min_gain_to_split=0, \n",
    "                         max_bin=256, max_depth=6)\n",
    "\n",
    "model.fit(X, y, eval_sets=[{'X': X_test, 'y': y_test},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "#### Prediction can be done via calling the .predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 s, sys: 650 ms, total: 2.02 s\n",
      "Wall time: 2.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-227.73753  , -139.2886   , -271.09726  , ..., -132.06668  ,\n",
       "        -209.25096  , -226.7468   ],\n",
       "       [-107.63527  , -105.17763  ,  -51.269665 , ..., -120.603195 ,\n",
       "        -108.78121  ,  -16.261744 ],\n",
       "       [ -37.47324  ,  -59.83011  ,  144.37334  , ...,   16.221537 ,\n",
       "         -27.90023  , -213.23357  ],\n",
       "       ...,\n",
       "       [ -79.836494 ,  138.32225  ,   85.83367  , ...,  230.75499  ,\n",
       "          37.589367 ,   16.244379 ],\n",
       "       [  -5.5796094,  138.75368  ,  246.4468   , ...,  150.21175  ,\n",
       "         174.16621  ,  205.89897  ],\n",
       "       [  -6.7977576,   40.970036 ,  167.97235  , ...,   96.029816 ,\n",
       "          27.76857  ,   11.001275 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for certan iterations can be done via calling the .predict_staged method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 373 ms, sys: 306 ms, total: 679 ms\n",
      "Wall time: 690 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_staged(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree leaves indicies prediction for certan iterations can be done via calling the .predict_leaves method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 ms, sys: 3.89 ms, total: 19.3 ms\n",
      "Wall time: 18.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_leaves(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 17,  5],\n",
       "       [50, 44, 14],\n",
       "       [32, 45, 54],\n",
       "       ...,\n",
       "       [54, 50, 15],\n",
       "       [30, 45,  5],\n",
       "       [60, 44, 13]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34.,   38.,   39.,   45.,   59.,   46., 5633.,   45.,   33.,\n",
       "         65.,   43.,   51.,   36.,   43.,   37., 5962., 5585.,   54.,\n",
       "         39., 5452.,   40.,   48.,   38.,   50.,   48.,   36.,   39.,\n",
       "         45.,   55.,   44.,   55.,   52.,   64.,   55.,   45.,   43.,\n",
       "       5880.,   44.,   48.,   42.,   44.,   41.,   57.,   56.,   44.,\n",
       "         41.,   33.,   42.,   46.,   44.,   47.,   48., 5824.,   35.,\n",
       "         45.,   52.,   44.,   41.,   56.,   45.,   62.,   42.,   46.,\n",
       "         40.,   47.,   47.,   35.,   50.,   49.,   54.,   45.,   34.,\n",
       "         32.,   56.,   54.,   51.,   61.,   42.,   58.,   53.,   57.,\n",
       "         37.,   45.,   70.,   63.,   36., 5635., 3571.,   47., 5825.,\n",
       "         45., 6166.,   42.,   45.,   57.,   47.,   45.,   56.,   30.,\n",
       "         56.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The trained model can be saved as pickle for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-227.73753  , -139.2886   , -271.09726  , ..., -132.06668  ,\n",
       "        -209.25096  , -226.7468   ],\n",
       "       [-107.63527  , -105.17763  ,  -51.269665 , ..., -120.603195 ,\n",
       "        -108.78121  ,  -16.261744 ],\n",
       "       [ -37.47324  ,  -59.83011  ,  144.37334  , ...,   16.221537 ,\n",
       "         -27.90023  , -213.23357  ],\n",
       "       ...,\n",
       "       [ -79.836494 ,  138.32225  ,   85.83367  , ...,  230.75499  ,\n",
       "          37.589367 ,   16.244379 ],\n",
       "       [  -5.5796094,  138.75368  ,  246.4468   , ...,  150.21175  ,\n",
       "         174.16621  ,  205.89897  ],\n",
       "       [  -6.7977576,   40.970036 ,  167.97235  , ...,   96.029816 ,\n",
       "          27.76857  ,   11.001275 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, '../data/temp_model.pkl')\n",
    "\n",
    "new_model = joblib.load('../data/temp_model.pkl')\n",
    "new_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "Also py_boost supports built in cross validation wrapper that produce out-of-fold prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:06:10] Stdout logging level is INFO.\n",
      "[10:06:10] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[10:06:10] Iter 0; Sample 0, rmse = 175.42609649872603; \n",
      "[10:06:10] Iter 10; Sample 0, rmse = 144.38437583641723; \n",
      "[10:06:10] Iter 20; Sample 0, rmse = 122.64889288531302; \n",
      "[10:06:10] Iter 30; Sample 0, rmse = 106.2448795667879; \n",
      "[10:06:11] Iter 40; Sample 0, rmse = 93.29088329381031; \n",
      "[10:06:11] Iter 50; Sample 0, rmse = 82.61964778368379; \n",
      "[10:06:11] Iter 60; Sample 0, rmse = 73.54036275397404; \n",
      "[10:06:11] Iter 70; Sample 0, rmse = 65.77099620580852; \n",
      "[10:06:12] Iter 80; Sample 0, rmse = 59.169712596698275; \n",
      "[10:06:12] Iter 90; Sample 0, rmse = 53.48868788517551; \n",
      "[10:06:12] Iter 99; Sample 0, rmse = 49.021571915744666; \n",
      "[10:06:12] Stdout logging level is INFO.\n",
      "[10:06:12] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[10:06:12] Iter 0; Sample 0, rmse = 176.46325625123137; \n",
      "[10:06:12] Iter 10; Sample 0, rmse = 145.3524019640615; \n",
      "[10:06:13] Iter 20; Sample 0, rmse = 123.36646151524265; \n",
      "[10:06:13] Iter 30; Sample 0, rmse = 106.86234613058204; \n",
      "[10:06:13] Iter 40; Sample 0, rmse = 93.6566447255517; \n",
      "[10:06:13] Iter 50; Sample 0, rmse = 82.77604696388298; \n",
      "[10:06:13] Iter 60; Sample 0, rmse = 73.58298608457713; \n",
      "[10:06:14] Iter 70; Sample 0, rmse = 65.82548645429591; \n",
      "[10:06:14] Iter 80; Sample 0, rmse = 59.21916967096181; \n",
      "[10:06:14] Iter 90; Sample 0, rmse = 53.52922603333239; \n",
      "[10:06:14] Iter 99; Sample 0, rmse = 49.106897505046156; \n",
      "[10:06:14] Stdout logging level is INFO.\n",
      "[10:06:14] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[10:06:14] Iter 0; Sample 0, rmse = 176.63708650647348; \n",
      "[10:06:15] Iter 10; Sample 0, rmse = 145.38862318590708; \n",
      "[10:06:15] Iter 20; Sample 0, rmse = 123.54989846549813; \n",
      "[10:06:15] Iter 30; Sample 0, rmse = 107.02731056292623; \n",
      "[10:06:15] Iter 40; Sample 0, rmse = 93.87664025696499; \n",
      "[10:06:16] Iter 50; Sample 0, rmse = 82.96531504408931; \n",
      "[10:06:16] Iter 60; Sample 0, rmse = 73.77596047946295; \n",
      "[10:06:16] Iter 70; Sample 0, rmse = 65.88829580207597; \n",
      "[10:06:16] Iter 80; Sample 0, rmse = 59.18102209073691; \n",
      "[10:06:17] Iter 90; Sample 0, rmse = 53.45941844189193; \n",
      "[10:06:17] Iter 99; Sample 0, rmse = 48.95995464323396; \n",
      "[10:06:17] Stdout logging level is INFO.\n",
      "[10:06:17] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[10:06:17] Iter 0; Sample 0, rmse = 175.13153670026327; \n",
      "[10:06:17] Iter 10; Sample 0, rmse = 144.0517702347049; \n",
      "[10:06:17] Iter 20; Sample 0, rmse = 122.17460762242344; \n",
      "[10:06:18] Iter 30; Sample 0, rmse = 105.62475983429208; \n",
      "[10:06:18] Iter 40; Sample 0, rmse = 92.34212896961414; \n",
      "[10:06:18] Iter 50; Sample 0, rmse = 81.6110380417051; \n",
      "[10:06:18] Iter 60; Sample 0, rmse = 72.48020166672337; \n",
      "[10:06:18] Iter 70; Sample 0, rmse = 64.79753568775662; \n",
      "[10:06:19] Iter 80; Sample 0, rmse = 58.19142974842088; \n",
      "[10:06:19] Iter 90; Sample 0, rmse = 52.5017363937333; \n",
      "[10:06:19] Iter 99; Sample 0, rmse = 48.07228119243873; \n",
      "[10:06:19] Stdout logging level is INFO.\n",
      "[10:06:19] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[10:06:19] Iter 0; Sample 0, rmse = 176.57360578894108; \n",
      "[10:06:20] Iter 10; Sample 0, rmse = 145.30557253817346; \n",
      "[10:06:20] Iter 20; Sample 0, rmse = 123.20943896890988; \n",
      "[10:06:20] Iter 30; Sample 0, rmse = 106.66035256052854; \n",
      "[10:06:20] Iter 40; Sample 0, rmse = 93.50557661256835; \n",
      "[10:06:20] Iter 50; Sample 0, rmse = 82.6622309915482; \n",
      "[10:06:21] Iter 60; Sample 0, rmse = 73.54897538962804; \n",
      "[10:06:21] Iter 70; Sample 0, rmse = 65.77099165111721; \n",
      "[10:06:21] Iter 80; Sample 0, rmse = 59.06227032295616; \n",
      "[10:06:21] Iter 90; Sample 0, rmse = 53.36436015287763; \n",
      "[10:06:22] Iter 99; Sample 0, rmse = 48.87589352875845; \n",
      "CPU times: user 12.9 s, sys: 1.55 s, total: 14.5 s\n",
      "Wall time: 13.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.28329104835014"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse')\n",
    "cv = CrossValidation(model)\n",
    "\n",
    "oof_pred = cv.fit_predict(X, y, cv=5)\n",
    "\n",
    "pred = cv.predict(X_test)\n",
    "((pred - y_test) ** 2).mean() ** .5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.04",
   "language": "python",
   "name": "rapids-22.04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
